# Copy this file to .env and fill in your keys.

# -----------------------------
# Preferred: Gemini (Google)
# -----------------------------
GEMINI_API_KEY=
GEMINI_MODEL=gemini-1.5-pro
GEMINI_BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai


# ----------------------------------------
# Alternative: OpenAI or Azure OpenAI
# ----------------------------------------
# Provide a JSON list of one or more endpoints.
# Example: OpenAI (uses the openai python SDK under the hood)
# OAI_CONFIG_LIST='[{"model":"gpt-4o-mini","api_key":"YOUR_OPENAI_KEY"}]'

# Example: Azure OpenAI
# OAI_CONFIG_LIST='[{"model":"gpt-4o-mini","api_key":"YOUR_AZURE_KEY","base_url":"https://<your-resource>.openai.azure.com/","api_type":"azure","api_version":"2024-02-01"}]'


# -----------------------------
# Runtime options (optional)
# -----------------------------
# Temperature for the Assistant LLM (0.0â€“1.0)
TEMPERATURE=0
# Max consecutive auto replies by the UserProxyAgent
MAX_AUTO_REPLIES=10
# Whether to run generated code inside Docker (requires Docker Desktop)
USE_DOCKER=false
